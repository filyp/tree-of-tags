{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "from engine import Engine, TreeClimber\n",
    "from html_builder import HTMLBuilder\n",
    "from krakow import krakow\n",
    "from krakow.utils import create_dendrogram, normalized_dasgupta_cost\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import textwrap\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = Data(alpha=1.6, use_cached_forum_data=True, forum=\"af\")\n",
    "# data = Data(alpha=15, use_cached_forum_data=True, forum=\"lw\")\n",
    "data = Data(alpha=9, use_cached_forum_data=True, forum=\"ea\")\n",
    "climber = TreeClimber(data)\n",
    "engine = Engine(data, climber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove tag named \"AI\"\n",
    "# tag_slug_to_id = dict()\n",
    "# for tag in data.tags.values():\n",
    "#     tag_slug_to_id[tag.slug] = tag._id\n",
    "# C = data.Tag_cooccurence.copy()\n",
    "# C.remove_node(tag_slug_to_id[\"ai\"])\n",
    "# G = C\n",
    "\n",
    "# # remove disconnected components\n",
    "# biggest_component = max(nx.connected_components(To_draw), key=len)\n",
    "# To_draw = To_draw.subgraph(biggest_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = data.Tag_cooccurence\n",
    "for node in G.nodes:\n",
    "    G.nodes[node][\"weight\"] = G[node][node][\"weight\"]\n",
    "    G.nodes[node][\"name\"] = data.tags[node][\"name\"]\n",
    "\n",
    "# remove self-edges\n",
    "G = nx.Graph(G)\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "nodes = sorted(G.nodes(), key=lambda x: G.nodes[x][\"weight\"], reverse=True)\n",
    "\n",
    "# for each edge calculate overlap\n",
    "for u, v, d in G.edges(data=True):\n",
    "    u_w = G.nodes[u][\"weight\"]\n",
    "    v_w = G.nodes[v][\"weight\"]\n",
    "    uv_w = d[\"weight\"]\n",
    "    d[\"overlap\"] = uv_w / (u_w + v_w - uv_w)\n",
    "    assert 0 <= d[\"overlap\"] <= 1\n",
    "\n",
    "# wrap node names\n",
    "for node in G.nodes:\n",
    "    G.nodes[node][\"name\"] = textwrap.fill(G.nodes[node][\"name\"], 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_nodes = 10000\n",
    "\n",
    "# create a subgraph with given nodes\n",
    "To_draw = G.subgraph(nodes[:num_of_nodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"../_site/interactive/tag_net.json\"\n",
    "_edges = nx.to_dict_of_dicts(To_draw)\n",
    "_nodes = {node: To_draw.nodes[node] for node in To_draw.nodes}\n",
    "json.dump((_nodes, _edges), open(filename, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * implement a hierarchichal spring layout\n",
    "attr = \"overlap\"\n",
    "repulsive_force = 0.1\n",
    "attractive_force = 0.1\n",
    "\n",
    "# initialize positions\n",
    "for node in To_draw.nodes:\n",
    "    To_draw.nodes[node][\"pos\"] = np.random.rand(2) * 2 - 1\n",
    "\n",
    "# calculate repulsive forces\n",
    "for i, node1 in enumerate(To_draw.nodes):\n",
    "    for j, node2 in enumerate(To_draw.nodes):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        pos1 = To_draw.nodes[node1][\"pos\"]\n",
    "        pos2 = To_draw.nodes[node2][\"pos\"]\n",
    "        diff = pos2 - pos1\n",
    "        dist = np.linalg.norm(diff)\n",
    "        if dist == 0:\n",
    "            dist = 0.00001\n",
    "        force = diff / dist * (1 / dist) ** 2 * repulsive_force\n",
    "        To_draw.nodes[node1][\"pos\"] -= force\n",
    "        To_draw.nodes[node2][\"pos\"] += force\n",
    "        \n",
    "# calculate attractive forces\n",
    "for u, v, d in To_draw.edges(data=True):\n",
    "    pos1 = To_draw.nodes[u][\"pos\"]\n",
    "    pos2 = To_draw.nodes[v][\"pos\"]\n",
    "    diff = pos2 - pos1\n",
    "    dist = np.linalg.norm(diff)\n",
    "    if dist == 0:\n",
    "        dist = 0.00001\n",
    "    force = diff / dist * (dist ** 2) * attractive_force * d[attr]\n",
    "    To_draw.nodes[u][\"pos\"] += force\n",
    "    To_draw.nodes[v][\"pos\"] -= force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {node: To_draw.nodes[node][\"pos\"] for node in To_draw.nodes}\n",
    "# pos = nx.spring_layout(\n",
    "#     To_draw, \n",
    "#     iterations=50,\n",
    "#     weight=\"overlap\",\n",
    "#     # pos=old_pos,\n",
    "#     # fixed=old_pos.keys(),\n",
    "# )\n",
    "\n",
    "max_weight = max([edge[2][\"weight\"] for edge in To_draw.edges(data=True)])\n",
    "plt.figure(figsize=(18, 18))\n",
    "nx.draw(\n",
    "    To_draw,\n",
    "    node_size=0,\n",
    "    # width=[edge[2][\"weight\"] / max_weight for edge in To_draw.edges(data=True)],\n",
    "    width=[edge[2][\"overlap\"] * 3 for edge in To_draw.edges(data=True)],\n",
    "    edge_color=\"blue\",\n",
    "    pos=pos,\n",
    ")\n",
    "\n",
    "# draw labels\n",
    "largest_tag_weight = max(node_data[\"weight\"] for _, node_data in To_draw.nodes(data=True))\n",
    "for node, (x, y) in pos.items():\n",
    "    name = To_draw.nodes[node][\"name\"]\n",
    "    size = (To_draw.nodes[node][\"weight\"] / largest_tag_weight) ** 0.4 * 25\n",
    "    plt.text(x, y, name, fontsize=size, color=\"black\", ha='center', va='center')\n",
    "\n",
    "# add pos data to graph\n",
    "for node, (x, y) in pos.items():\n",
    "    To_draw.nodes[node][\"pos\"] = (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the distribution of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "big_up_ratios = []\n",
    "sma_up_ratios = []\n",
    "sma_down_ratios = []\n",
    "big_down_ratios = []\n",
    "\n",
    "for post in data.posts.values():\n",
    "    num_of_votes = len(post.allVotes)\n",
    "    vote_types = [vote[\"voteType\"] for vote in post.allVotes]\n",
    "    vote_types = Counter(vote_types)\n",
    "    # if post._id == \"\":\n",
    "    #     print(post.title)\n",
    "    #     print(vote_types[\"bigDownvote\"], vote_types[\"smallDownvote\"], vote_types[\"smallUpvote\"], vote_types[\"bigUpvote\"])\n",
    "    if num_of_votes == 0:\n",
    "        continue\n",
    "    big_up_ratios.append(vote_types[\"bigUpvote\"] / num_of_votes)\n",
    "    sma_up_ratios.append(vote_types[\"smallUpvote\"] / num_of_votes)\n",
    "    sma_down_ratios.append(vote_types[\"smallDownvote\"] / num_of_votes)\n",
    "    big_down_ratios.append(vote_types[\"bigDownvote\"] / num_of_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of vote ratios\n",
    "plt.hist(big_up_ratios, bins=20, alpha=0.5, label=\"bigUpvote\")\n",
    "plt.hist(sma_up_ratios, bins=20, alpha=0.5, label=\"smallUpvote\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(big_down_ratios, bins=20, range=(0, 1), alpha=0.5, label=\"bigDownvote\")\n",
    "plt.hist(sma_down_ratios, bins=20, range=(0, 1),alpha=0.5, label=\"smallDownvote\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze cracy of posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_posts = data.posts.values()\n",
    "# filter out posts where one of the scores is negative\n",
    "# find the median ratio\n",
    "_demo = np.array([post[\"democraticScore\"] for post in all_posts])\n",
    "_meri = np.array([post[\"meritocraticScore\"] for post in all_posts])\n",
    "_regu = np.array([post[\"baseScore\"] for post in all_posts])\n",
    "# median_ratio = np.median(_meri / _demo)\n",
    "\n",
    "# make the axes equal and rectangular\n",
    "plt.figure(figsize=(10,10))\n",
    "# chop off at 0\n",
    "plt.xlim(-50, 600)\n",
    "plt.ylim(-50, 600)\n",
    "# plot line with a slope of the median ratio\n",
    "plt.plot([-50, 600], [-50, 600], color=\"white\", linewidth=0.5)\n",
    "# plot 0 lines\n",
    "plt.plot([-50, 600], [0, 0], color=\"white\", linewidth=0.5)\n",
    "plt.plot([0, 0], [-50, 600], color=\"white\", linewidth=0.5)\n",
    "plt.scatter(_demo, _meri, s=1)\n",
    "# add labels\n",
    "plt.xlabel(\"Democratic score\")\n",
    "plt.ylabel(\"Meritocratic score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_big_vote_component = np.mean([p.baseScore - p.smallBalance for p in all_posts])\n",
    "avg_big_balance = np.mean([p.bigBalance for p in all_posts])\n",
    "avg_vote_power = avg_big_vote_component / avg_big_balance\n",
    "avg_vote_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between meritocratic and democratic scores\n",
    "from scipy.stats import pearsonr\n",
    "pearsonr([p.meritocraticScore for p in all_posts], [p.democraticScore for p in all_posts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda p: p.democraticScore\n",
    "\n",
    "sorted_posts = sorted([post for post in filtered_posts if post.democraticScore*median_ratio > post.meritocraticScore], key=f, reverse=True)[:25]\n",
    "for post in sorted_posts:\n",
    "    print(f\"{post.bigDownvotes:3} {post.smallDownvotes:3} {post.smallUpvotes:3} {post.bigUpvotes:3}     {post.democraticScore:3} {post.baseScore:3} {post.meritocraticScore:3}     {post.cracy:.3f} {post.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda p: p.meritocraticScore\n",
    "\n",
    "sorted_posts = sorted([post for post in filtered_posts if post.democraticScore*median_ratio <= post.meritocraticScore], key=f, reverse=True)[:25]\n",
    "for post in sorted_posts:\n",
    "    print(f\"{post.bigDownvotes:3} {post.smallDownvotes:3} {post.smallUpvotes:3} {post.bigUpvotes:3}     {post.democraticScore:3} {post.baseScore:3} {post.meritocraticScore:3}     {post.cracy:.3f} {post.title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze overlap of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find tags with highest cooccurence\n",
    "cooccurence_data = [(u, v, edge_data[\"weight\"]) for u, v, edge_data in data.Tag_cooccurence.edges(data=True)]\n",
    "\n",
    "# normalize cooccurences by the size of two tags\n",
    "normalized_cooccurences = dict()\n",
    "for u, v, cooccurence in cooccurence_data:\n",
    "    u_size = data.Tag_cooccurence[u][u][\"weight\"]\n",
    "    v_size = data.Tag_cooccurence[v][v][\"weight\"]\n",
    "    sum_of_occurence = u_size + v_size - cooccurence\n",
    "    normalized_cooccurences[(u, v)] = cooccurence / sum_of_occurence\n",
    "\n",
    "# sort by normalized cooccurence\n",
    "sorted_cooccurences = sorted(normalized_cooccurences.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# print tags with highest overlap\n",
    "for (u, v), cooccurence in sorted_cooccurences:\n",
    "    if u == v:\n",
    "        continue\n",
    "    print(f'{data.tags[u][\"name\"]:30} {data.tags[v][\"name\"]:30} {cooccurence:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in data.posts.values():\n",
    "    print(post[\"commentCount\"])\n",
    "    # if post[\"commentCount\"] is None:\n",
    "    #     print(post[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_scores = dict()\n",
    "for post in data.posts.values():\n",
    "    for tag, relevance in post[\"tagRelevance\"].items():\n",
    "        if tag not in tag_scores:\n",
    "            tag_scores[tag] = []\n",
    "        tag_scores[tag].append((post[\"baseScore\"], relevance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags_sorted_by_quality = sorted(tag_quality.items(), key=lambda x: np.average(x[1][0], weights=x[1][1]), reverse=True)\n",
    "\n",
    "tag_qualities = dict()\n",
    "for tag, scores_and_relevances in tag_scores.items():\n",
    "    scores, relevances = zip(*scores_and_relevances)\n",
    "    quality = np.average(scores, weights=relevances)\n",
    "    tag_qualities[tag] = quality\n",
    "\n",
    "tags_sorted_by_quality = sorted(tag_qualities.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag_id, quality in tags_sorted_by_quality:\n",
    "    scores = [score for score, relevance in tag_scores[tag_id]]\n",
    "    if len(scores) < 2:\n",
    "        continue\n",
    "    if tag_id not in data.tags:\n",
    "        print(f\"{tag_id} not in tags\")\n",
    "        continue\n",
    "    print(f'{data.tags[tag_id][\"name\"]:50} {quality:.0f}     {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [post[\"baseScore\"] for post in data.posts.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of scores\n",
    "plt.hist(scores, bins=100, range=(-10, 200))\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_scores = np.log(np.clip(scores, 1, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of log scores\n",
    "plt.hist(log_scores, bins=50)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_posts = sorted(data.posts.values(), key=lambda x: x[\"baseScore\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_posts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which percentile a score 52\n",
    "percentile = np.percentile(scores, 80.2)\n",
    "percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate tags present in posts, but not listed by GraphQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in data.posts.values():\n",
    "    if \"ZJEM3pibQmic8Rp5G\" in post[\"tagRelevance\"]:\n",
    "        print(post)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in data.tags.values():\n",
    "    if tag[\"name\"] == \"Community\":\n",
    "        print(tag)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tags[\"Sgx48Pf8PzmTxSEEG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Community\" \"Frontpage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.posts[\"rDAZancpWpMwxjoFg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
